# Phase 5: Analytics, Reporting & Opus Deep Analysis

**Goal**: Deep analytics for MLA's team, weekly reports, and Opus-powered trend analysis.

**Deliverable**: Auto-generated weekly constituency report. Opus 4.6 used for deep trend analysis and complex complaint resolution patterns.

---

## P5-S1: Weekly Constituency Report

**As a** developer
**I want** an automated weekly constituency report generated by Opus 4.6 and posted to the admin WhatsApp group every Monday at 9 AM
**So that** the MLA's team receives AI-generated narrative analysis of complaint trends, resolution metrics, and actionable recommendations

### Dependencies

| Depends On | Story Title | Why |
|------------|-------------|-----|
| P2-S5 | Daily summary scheduled task | Need scheduler infrastructure and summary generation patterns |

> ⛔ **DO NOT START** this story until all dependencies above are marked completed.

### Acceptance Criteria

1. [ ] Scheduled task (nanoclaw scheduler): every Monday 9 AM
2. [ ] Agent container with Opus 4.6 generates comprehensive report
3. [ ] Report includes: complaints received this week vs last week
4. [ ] Report includes: resolution rate and average resolution time
5. [ ] Report includes: top 5 complaint categories
6. [ ] Report includes: ward-wise complaint distribution
7. [ ] Report includes: aging complaints requiring attention
8. [ ] Report includes: AI-generated narrative analysis of trends and recommendations
9. [ ] Summary posted to admin WhatsApp group
10. [ ] Report stored in dashboard for download

### Files & Scope

| File | Action | What Changes |
|------|--------|-------------|
| `src/task-scheduler.ts` | Extend | Register weekly report task for Monday 9 AM |
| `src/admin-handler.ts` | Extend | Add weekly report generation and posting |
| `src/api/reports.ts` | New | API endpoint to retrieve stored reports |

### Testing Requirements (TDD Workflow)

Use the `/test-driven-development` skill.

1. **Write tests FIRST**:
   - Test: weekly task registered for Monday 9 AM
   - Test: report includes week-over-week comparison
   - Test: report includes resolution rate calculation
   - Test: report includes average resolution time
   - Test: report lists top 5 categories by count
   - Test: report includes ward-wise distribution
   - Test: report identifies aging complaints (> 7, > 14, > 30 days)
   - Test: report uses Opus 4.6 model
   - Test: report posted to admin group
   - Test: report stored and retrievable via API
   - Edge case: first week with no previous data — handles comparison gracefully
   - Edge case: no complaints this week — report handles empty state
2. **Run tests** — confirm they fail
3. **Implement** — report generator with Opus integration
4. **Refactor** — optimize report queries

### Development Workflow

#### Step 1: Architecture Review
Use `/writing-plans` to plan the weekly report system.
Use `/requesting-code-review` to validate:
- Report content structure
- Opus 4.6 integration approach
- Storage and retrieval strategy

#### Step 2: TDD Implementation
Use `/test-driven-development` — tests first, then implement.

#### Step 3: Code Review
Use `/requesting-code-review`. Process feedback via `/receiving-code-review`.

#### Step 4: Verification
Use `/verification-before-completion`:
- Run full test suite
- Generate test report with sample data

#### Step 5: Mark Complete
Check off all acceptance criteria. Update STORIES_INDEX.md.

---

## P5-S2: Opus 4.6 for Deep Analysis Tasks

**As a** developer
**I want** a dedicated analyst agent group configured with Opus 4.6 for analytical work
**So that** complex analysis tasks (reports, trend detection, anomaly analysis) use the most capable model

### Dependencies

| Depends On | Story Title | Why |
|------------|-------------|-----|
| P5-S1 | Weekly constituency report | Need the report system to understand the analytical workload |

> ⛔ **DO NOT START** this story until all dependencies above are marked completed.

### Acceptance Criteria

1. [ ] `groups/analyst/CLAUDE.md` created — separate agent group for analytical work
2. [ ] Analyst agent configured to use Opus 4.6 model
3. [ ] Analyst agent has read-only access to complaint database
4. [ ] Scheduled tasks trigger analyst agent for reports and trend analysis
5. [ ] `container/agent-runner/src/index.ts` settings support Opus model selection
6. [ ] Analyst agent runs without impacting complaint bot performance

### Files & Scope

| File | Action | What Changes |
|------|--------|-------------|
| `groups/analyst/CLAUDE.md` | New | Analyst agent brain — analytical instructions, read-only DB access |
| `container/agent-runner/src/index.ts` | Modify | Add model selection support for Opus 4.6 |

### Testing Requirements (TDD Workflow)

Use the `/test-driven-development` skill.

1. **Write tests FIRST**:
   - Test: analyst CLAUDE.md exists with analytical instructions
   - Test: analyst agent configured for Opus 4.6 model
   - Test: analyst agent has read-only DB access (cannot write/delete)
   - Test: analyst container spawns independently from complaint containers
   - Test: model selection in agent-runner supports both Sonnet and Opus
   - Edge case: analyst agent failure doesn't affect complaint bot
2. **Run tests** — confirm they fail
3. **Implement** — analyst agent configuration
4. **Refactor** — ensure clean model selection

### Development Workflow

#### Step 1: Architecture Review
Use `/writing-plans` to plan the analyst agent.
Use `/requesting-code-review` to validate:
- CLAUDE.md content for analytical tasks
- Read-only DB access enforcement
- Model selection mechanism

#### Step 2: TDD Implementation
Use `/test-driven-development` — tests first, then implement.

#### Step 3: Code Review
Use `/requesting-code-review`. Process feedback via `/receiving-code-review`.

#### Step 4: Verification
Use `/verification-before-completion`:
- Run full test suite
- Verify analyst agent runs with Opus model

#### Step 5: Mark Complete
Check off all acceptance criteria. Update STORIES_INDEX.md.

---

## P5-S3: Complaint Trend Analysis

**As a** developer
**I want** trend charts in the dashboard and automatic spike alerts in the admin group
**So that** the MLA's team can visualize complaint patterns and be alerted when unusual spikes occur

### Dependencies

| Depends On | Story Title | Why |
|------------|-------------|-----|
| P4-S2 | Dashboard frontend | Need the dashboard to add trend charts to |
| P5-S2 | Opus 4.6 for deep analysis tasks | Need the analyst agent for narrative trend summaries |

> ⛔ **DO NOT START** this story until all dependencies above are marked completed.

### Acceptance Criteria

1. [ ] Dashboard page: trend charts by category, ward, time
2. [ ] Alert: if a category spikes (10x more than usual), auto-flag in admin group
3. [ ] Opus agent generates weekly narrative summary explaining patterns
4. [ ] Trend spike alert triggered when category volume exceeds 3x baseline
5. [ ] Opus 4.6 generates trend insights that Sonnet alone couldn't produce

### Files & Scope

| File | Action | What Changes |
|------|--------|-------------|
| `dashboard/src/pages/Trends.tsx` | New | Trend analysis page with charts |
| `src/api/trends.ts` | New | Trend data API endpoint |
| `src/admin-handler.ts` | Extend | Add spike alert logic |

### Testing Requirements (TDD Workflow)

Use the `/test-driven-development` skill.

1. **Write tests FIRST**:
   - Test: trend API returns data by category over time
   - Test: trend API returns data by ward over time
   - Test: spike detection triggers at 3x baseline volume
   - Test: spike alert posted to admin group with category details
   - Test: trend charts render in dashboard
   - Edge case: insufficient data for baseline — no false alerts
   - Edge case: new category with no baseline handled correctly
2. **Run tests** — confirm they fail
3. **Implement** — trend analysis and alerts
4. **Refactor** — optimize trend queries

### Development Workflow

#### Step 1: Architecture Review
Use `/writing-plans` to plan the trend analysis system.
Use `/requesting-code-review` to validate:
- Spike detection algorithm
- Baseline calculation approach
- Chart data structure

#### Step 2: TDD Implementation
Use `/test-driven-development` — tests first, then implement.

#### Step 3: Code Review
Use `/requesting-code-review`. Process feedback via `/receiving-code-review`.

#### Step 4: Verification
Use `/verification-before-completion`:
- Run full test suite
- Test spike detection with sample data

#### Step 5: Mark Complete
Check off all acceptance criteria. Update STORIES_INDEX.md.

---

## P5-S4: Export Functionality

**As a** developer
**I want** CSV export of complaints with filters for government reporting
**So that** the MLA's team can generate filtered reports in Excel-compatible format for official submissions

### Dependencies

| Depends On | Story Title | Why |
|------------|-------------|-----|
| P4-S1 | Dashboard API | Need the API infrastructure to add export endpoint |

> ⛔ **DO NOT START** this story until all dependencies above are marked completed.

### Acceptance Criteria

1. [ ] CSV export of complaints with applied filters
2. [ ] Excel-compatible format for government reporting
3. [ ] API endpoint: `GET /api/export?format=csv&status=open&from=...&to=...`
4. [ ] CSV export works with all filters (status, category, date range, ward)
5. [ ] Export includes all complaint fields needed for reporting

### Files & Scope

| File | Action | What Changes |
|------|--------|-------------|
| `src/api/export.ts` | New | Export endpoint with CSV generation |
| `dashboard/src/components/ExportButton.tsx` | New | Export button in dashboard UI |

### Testing Requirements (TDD Workflow)

Use the `/test-driven-development` skill.

1. **Write tests FIRST**:
   - Test: `GET /api/export?format=csv` returns valid CSV
   - Test: CSV contains all complaint fields (ID, category, status, description, etc.)
   - Test: filters work in export (status, category, date range)
   - Test: CSV header row matches expected columns
   - Test: CSV opens correctly in Excel (proper encoding for Marathi/Hindi text)
   - Test: export with no matching complaints returns headers only
   - Edge case: large export (1000+ complaints) doesn't timeout
   - Edge case: special characters in complaint text properly escaped in CSV
2. **Run tests** — confirm they fail
3. **Implement** — export endpoint and CSV generation
4. **Refactor** — optimize for large datasets

### Development Workflow

#### Step 1: Architecture Review
Use `/writing-plans` to plan the export system.
Use `/requesting-code-review` to validate:
- CSV format and encoding (UTF-8 BOM for Excel)
- Filter parameter handling
- Memory management for large exports

#### Step 2: TDD Implementation
Use `/test-driven-development` — tests first, then implement.

#### Step 3: Code Review
Use `/requesting-code-review`. Process feedback via `/receiving-code-review`.

#### Step 4: Verification
Use `/verification-before-completion`:
- Run full test suite
- Test export with sample data
- Open exported CSV in Excel to verify formatting

#### Step 5: Mark Complete
Check off all acceptance criteria. Update STORIES_INDEX.md.
Note: Phase 5 is now complete.
